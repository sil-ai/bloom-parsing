{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "UOyTv72Z1FuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBR_ghB90y4I"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#All Languages audio"
      ],
      "metadata": {
        "id": "Rl6HNVVafcTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install boto3\n",
        "!pip install beautifulsoup4\n",
        "import boto3\n",
        "import getpass\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import pickle"
      ],
      "metadata": {
        "id": "EomRbbVQfpTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "access_key = getpass.getpass('key')\n",
        "secret = getpass.getpass('secret')"
      ],
      "metadata": {
        "id": "vMzhySd1fscb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = boto3.session.Session()\n",
        "client = session.client('s3',\n",
        "                        region_name='us-east-1',\n",
        "                        aws_access_key_id=access_key,\n",
        "                        aws_secret_access_key=secret)"
      ],
      "metadata": {
        "id": "Pc-bRa0HglYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3 = boto3.resource('s3',                        \n",
        "                    region_name='us-east-1',\n",
        "                    aws_access_key_id=access_key,\n",
        "                    aws_secret_access_key=secret)\n",
        "bucket = s3.Bucket('bloom-speech')\n",
        "#len(list(bucket.objects.all()))"
      ],
      "metadata": {
        "id": "g0eNJUHJhGsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in bucket.objects.all():\n",
        "  fname = obj.key\n",
        "  s3.Object('bloom-speech',fname).Acl().put(ACL='public-read')"
      ],
      "metadata": {
        "id": "zMMwcQxcGxAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in tqdm(bucket.objects.limit(25000)):\n",
        "  fname = obj.key\n",
        "  if fname.startswith('bloom_downloads') and (fname.endswith('.htm') or fname.endswith('meta.json')):\n",
        "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "    client.download_file('bloom-raw-data', fname, fname)"
      ],
      "metadata": {
        "id": "n-57jCmhi4s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import csv\n",
        "\n",
        "books = os.listdir('/content/bloom_downloads')\n",
        "licenses = set()\n",
        "\n",
        "for book in tqdm(books):\n",
        "  metapath = os.path.join('/content','bloom_downloads', book, 'meta.json')\n",
        "  if os.path.isfile(metapath):\n",
        "    with open(metapath, 'rb') as jsonfile:\n",
        "      meta = json.load(jsonfile)\n",
        "      licenses.add(meta.get('license'))\n",
        "      langs = meta.get('language-display-names',[])\n",
        "  bookpath = os.path.join('/content','bloom_downloads', book)\n",
        "  bookfiles = os.listdir(bookpath)\n",
        "  for lang in langs:\n",
        "    for f in bookfiles:\n",
        "      if f.endswith('.htm'):\n",
        "        with open(os.path.join(bookpath,f),'rb') as htmlfile:\n",
        "          soup = BeautifulSoup(htmlfile, 'html.parser')\n",
        "        for hit in soup.findAll(attrs={'lang': lang}):\n",
        "          print(lang)\n",
        "          for sent in hit.findAll(attrs={'class' : 'audio-sentence'}):\n",
        "            #print(sent)\n",
        "            print(sent.get_text().strip())\n",
        "          break"
      ],
      "metadata": {
        "id": "GtT-JTHa6PS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in tqdm(bucket.objects.all()):\n",
        "  fname = obj.key\n",
        "  if fname.startswith('bloom_downloads') and (fname.endswith('.htm') or fname.endswith('meta.json')):\n",
        "    os.makedirs(os.path.dirname(os.path.join('/content/drive/MyDrive/bloom',fname)), exist_ok=True)\n",
        "    client.download_file('bloom-raw-data', fname, os.path.join('/content/drive/MyDrive/bloom',fname))"
      ],
      "metadata": {
        "id": "_BJQbTYJitKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_title(title):\n",
        "    invalid = '<>:\"/\\|?*'\n",
        "    removes = '()'\n",
        "    for char in invalid:\n",
        "      title = title.replace(char, \" \")\n",
        "    for char in removes:\n",
        "      title = title.replace(char, '')\n",
        "    if len(title) > 50:\n",
        "      title = title[0:50]\n",
        "    return(title)"
      ],
      "metadata": {
        "id": "tu6Z8DSTbwYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/valid_urls.pkl', 'rb') as pklfile:\n",
        "          urls = pickle.load(pklfile)"
      ],
      "metadata": {
        "id": "lsdmsfkGfip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/valid_urls.pkl', 'rb') as pklfile:\n",
        "          urls = pickle.load(pklfile)"
      ],
      "metadata": {
        "id": "Lr6y8iB20NPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZtH8oMH0LSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = []"
      ],
      "metadata": {
        "id": "0upbpPICXFfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "bloom_dir = '/content/drive/MyDrive/bloom/bloom_downloads'\n",
        "books = os.listdir(bloom_dir)\n",
        "bloom_audio = {}\n",
        "\n",
        "for book in tqdm(books):\n",
        "  metapath = os.path.join(bloom_dir, book, 'meta.json')\n",
        "  if os.path.isfile(metapath):\n",
        "    with open(metapath, 'rb') as jsonfile:\n",
        "      meta = json.load(jsonfile)\n",
        "      if meta.get('language-display-names') and meta.get('license') not in ['custom', 'ask', None]: \n",
        "        for lang in meta['language-display-names'].keys():\n",
        "          if f'talkingBook:{lang}' in meta['features']:\n",
        "            #cak_tbs.append(book)\n",
        "            downsrc = meta.get('downloadSource')\n",
        "            if downsrc == None:\n",
        "              print(f'{book} missing downloadSource')\n",
        "            try:\n",
        "              titles_dict = json.loads(meta['allTitles'].replace(\"\\n\", \" \"))\n",
        "            except:\n",
        "              print(meta['allTitles'], type(meta['allTitles']))\n",
        "              break\n",
        "            if titles_dict.get(lang):\n",
        "              title = titles_dict.get(lang)\n",
        "              title = clean_title(title)\n",
        "              title_path = os.path.join(bloom_dir, book, title.strip() + '.htm')\n",
        "              if not os.path.isfile(title_path):\n",
        "                #print(f'{title_path} not found in {os.listdir(os.path.join(\"/content\",\"bloom_downloads\", book))} trying book')\n",
        "                title = book\n",
        "                title = clean_title(title)\n",
        "                title_path = os.path.join(bloom_dir, book, title.strip() + '.htm')\n",
        "              if not os.path.isfile(title_path):\n",
        "                #print(f'{title_path} also not found')\n",
        "                titles = [x for x in os.listdir(os.path.join(bloom_dir, book)) if x.endswith('.htm')]\n",
        "                if len(titles)>0:\n",
        "                  title=titles[0]\n",
        "                  title_path = os.path.join(bloom_dir, book, title)\n",
        "            else:\n",
        "              print(f'no {lang} title for {book}')\n",
        "              title = book\n",
        "              title = clean_title(title)\n",
        "              title_path = os.path.join(bloom_dir, book, title.strip() + '.htm')\n",
        "\n",
        "            try:\n",
        "              with open(title_path,'rb') as htmlfile:\n",
        "                soup = BeautifulSoup(htmlfile, 'html.parser')\n",
        "              #with open('/content/drive/MyDrive/bloom/all-lang-files.csv', 'a', encoding='utf-16') as csvfile:\n",
        "                #writer = csv.writer(csvfile, dialect='excel', delimiter='\\t')\n",
        "              for hit in soup.findAll(attrs={'lang': lang, 'class' : 'audio-sentence'}):\n",
        "                fileid = hit.get_attribute_list('id')[0]\n",
        "                text = hit.get_text().strip()                 \n",
        "                if text != '':\n",
        "                  url = f'https://s3.amazonaws.com/bloomharvest/{downsrc}/bloomdigital/audio/{fileid}.mp3'\n",
        "                  if url not in urls:\n",
        "                    page = requests.get(url)\n",
        "                    if page.status_code == 200:\n",
        "                      if not bloom_audio.get(lang):\n",
        "                        bloom_audio[lang]=[] \n",
        "                      bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "                      urls.append(url)\n",
        "                  else:\n",
        "                    if {\"book\": book, \"url\": url, \"text\": text} not in bloom_audio.get(lang,[]):\n",
        "                      if not bloom_audio.get(lang):\n",
        "                        bloom_audio[lang]=[] \n",
        "                      bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "              for lhit in soup.findAll(attrs={'lang':lang}):\n",
        "                for hit in lhit.findAll(attrs={'class' : 'audio-sentence'}):\n",
        "                  fileid = hit.get_attribute_list('id')[0]\n",
        "                  text = hit.get_text().strip()                 \n",
        "                  if text != '':\n",
        "                    url = f'https://s3.amazonaws.com/bloomharvest/{downsrc}/bloomdigital/audio/{fileid}.mp3'\n",
        "                    if url not in urls:\n",
        "                      page = requests.get(url)\n",
        "                      if page.status_code == 200:\n",
        "                        if not bloom_audio.get(lang):\n",
        "                          bloom_audio[lang]=[] \n",
        "                        bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "                        urls.append(url)\n",
        "                    else:\n",
        "                      if {\"book\": book, \"url\": url, \"text\": text} not in bloom_audio.get(lang,[]):\n",
        "                        if not bloom_audio.get(lang):\n",
        "                          bloom_audio[lang]=[] \n",
        "                        bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "\n",
        "            except:\n",
        "              print(print(f'{title_path} failed download'))\n",
        "              raise\n",
        "\n",
        "        with open('/content/drive/MyDrive/bloom/valid_urls.pkl', 'wb') as pklfile:\n",
        "          pickle.dump(urls, pklfile)\n",
        "                      \n",
        "          #print(book)\n",
        "\n",
        "      \n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "20qYvldMfvbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parents_havelang(tag):\n",
        "  answer = False\n",
        "  for parent in tag.parents:\n",
        "    if parent.attrs.get('lang') and parent.attrs.get('lang') != '*':\n",
        "      answer = True\n",
        "      break\n",
        "  return(answer) "
      ],
      "metadata": {
        "id": "6wjt6PbRo8Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "bloom_dir = '/content/drive/MyDrive/bloom/bloom_downloads'\n",
        "books = os.listdir(bloom_dir)\n",
        "bloom_audio = {}\n",
        "badurls = []\n",
        "prob_books = {}\n",
        "statcodes = {}\n",
        "\n",
        "tb_set = set()\n",
        "tb_lds = {}\n",
        "missing_lang = 0\n",
        "has_lang = 0\n",
        "ml_books = set()\n",
        "hl_books = set()\n",
        "lang_set = set()\n",
        "\n",
        "for book in tqdm(books):\n",
        "  metapath = os.path.join(bloom_dir, book, 'meta.json')\n",
        "  if os.path.isfile(metapath):\n",
        "    with open(metapath, 'rb') as jsonfile:\n",
        "      meta = json.load(jsonfile)\n",
        "      if meta.get('features') and meta.get('license') not in ['custom', 'ask', None]:\n",
        "        for feat in meta['features'] :\n",
        "          if feat.startswith('talkingBook'):\n",
        "            downsrc = meta.get('downloadSource')\n",
        "            if downsrc == None:\n",
        "              print(f'{book} missing downloadSource')\n",
        "\n",
        "            titles = [x for x in os.listdir(os.path.join(bloom_dir, book)) if x.endswith('.htm')]\n",
        "            if titles == []:\n",
        "              print(f'{book} lacks .htm')\n",
        "              print(os.listdir(os.path.join(bloom_dir, book)))\n",
        "            else:\n",
        "              title=titles[0]\n",
        "              title_path = os.path.join(bloom_dir, book, title)\n",
        "\n",
        "            try:\n",
        "              with open(title_path,'rb') as htmlfile:\n",
        "                soup = BeautifulSoup(htmlfile, 'html.parser')\n",
        "\n",
        "              for hit in soup.find_all(attrs={'class' : 'audio-sentence'}):\n",
        "                if hit != []:\n",
        "                  if hit.attrs.get('lang') and hit.attrs.get('lang')!= '*':\n",
        "                    lang = hit.attrs.get('lang')\n",
        "                    fileid = hit.get_attribute_list('id')[0]\n",
        "                    text = hit.get_text().strip()\n",
        "                    has_lang += 1\n",
        "                    lang_set.add(lang)\n",
        "                    hl_books.add(book)\n",
        "                  elif parents_havelang(hit): \n",
        "                    for parent in hit.parents:\n",
        "                      if parent.attrs.get('lang') and parent.attrs.get('lang') != '*':\n",
        "                        lang = parent.attrs.get('lang')\n",
        "                        break\n",
        "                    fileid = hit.get_attribute_list('id')[0]\n",
        "                    text = hit.get_text().strip()\n",
        "                    has_lang += 1\n",
        "                    lang_set.add(lang)\n",
        "                    hl_books.add(book)\n",
        "                  elif len([x for x in meta['features'] if x.startswith('talkingBook:')]) == 1:\n",
        "                    lang = [x.split(':')[1] for x in meta['features'] if x.startswith('talkingBook:')][0]\n",
        "                    fileid = hit.get_attribute_list('id')[0]\n",
        "                    text = hit.get_text().strip()\n",
        "                    \n",
        "              \n",
        "                if text != '':\n",
        "                  url = f'https://s3.amazonaws.com/bloomharvest/{downsrc}/bloomdigital/audio/{fileid}.mp3'\n",
        "                  if url not in urls:\n",
        "                    page = requests.get(url)\n",
        "                    if page.status_code == 200:\n",
        "                      if not bloom_audio.get(lang):\n",
        "                        bloom_audio[lang]=[] \n",
        "                      bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "                      urls.append(url)\n",
        "                    else:\n",
        "                      badurls.append(url)\n",
        "                      if not statcodes.get(page.status_code):\n",
        "                        statcodes[page.status_code] = 0\n",
        "                      statcodes[page.status_code] += 1\n",
        "                      if not prob_books.get(book):\n",
        "                        prob_books[book] = set()\n",
        "                      prob_books[book].add(url)\n",
        "                  else:\n",
        "                    if {\"book\": book, \"url\": url, \"text\": text} not in bloom_audio.get(lang,[]):\n",
        "                      if not bloom_audio.get(lang):\n",
        "                        bloom_audio[lang]=[] \n",
        "                      bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "\n",
        "            except:\n",
        "              print(print(f'{title_path} failed download'))\n",
        "              raise\n",
        "            break\n",
        "\n",
        "        with open('/content/drive/MyDrive/bloom/valid_urls.pkl', 'wb') as pklfile:\n",
        "          pickle.dump(urls, pklfile)\n",
        "                      \n",
        "          #print(book)\n",
        "\n",
        "      \n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "OvKZmzA7ufUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/all-lang-files-v2.json', 'w', encoding='utf-8') as outfile:\n",
        "  json.dump(bloom_audio,outfile, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "uAAbOgGpPup4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/all-lang-files-v2.json', 'r', encoding='utf-8') as infile:\n",
        "  bloom_audio = json.load(infile)"
      ],
      "metadata": {
        "id": "pYF0hfVWMkXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(statcodes)"
      ],
      "metadata": {
        "id": "US2BJJ6hpx-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if {\"book\": book, \"url\": url, \"text\": text} not in bloom_audio.get(lang,[]):\n",
        "  print(book)"
      ],
      "metadata": {
        "id": "Rq4ldCiiXXWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resource_list = [f'{x}: {len(y)}' for x,y in bloom_audio.items()]\n",
        "resource_list.sort()\n",
        "print(resource_list)"
      ],
      "metadata": {
        "id": "wkICDALwczlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(bloom_audio.keys()))"
      ],
      "metadata": {
        "id": "bvk13zV9h9Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_audio['nsn'][11]"
      ],
      "metadata": {
        "id": "0SfO9CsNNLbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = requests.get(bloom_audio['nsn'][11]['url'])"
      ],
      "metadata": {
        "id": "7Vckm4BXJa0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page.content"
      ],
      "metadata": {
        "id": "wxTM7roIJhsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_to_iso.get('en')"
      ],
      "metadata": {
        "id": "L8_AW5qlfkmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_dir = '/content/drive/MyDrive/bloom/bloom_downloads'\n",
        "books = os.listdir(bloom_dir)\n",
        "book_info = {}\n",
        "\n",
        "for lang in tqdm(list(bloom_audio.keys())):\n",
        "    tag = lang.split('-')[0]\n",
        "    iso = tag_to_iso.get(tag)\n",
        "    if not book_info.get(iso):\n",
        "      book_info[iso]={}\n",
        "    if iso:\n",
        "      for book in {x['book'] for x in bloom_speech[iso]}:\n",
        "        metapath = os.path.join(bloom_dir, book, 'meta.json')\n",
        "        if os.path.isfile(metapath):\n",
        "          with open(metapath, 'rb') as jsonfile:\n",
        "            meta = json.load(jsonfile)\n",
        "          license = meta.get('license')\n",
        "          copyright = meta.get('copyright')\n",
        "          credits = meta.get('credits')\n",
        "          instance = meta.get('bookInstanceId')\n",
        "          book_info[iso][book] = {'bloomLanguageTag': lang, 'license': license, 'copyright':copyright, 'credits':credits, 'instance':instance}\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/book_info_v2.json', 'w', encoding='utf-8') as jsonfile:\n",
        "  json.dump(book_info, jsonfile)"
      ],
      "metadata": {
        "id": "Xmg7uLVxajn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_speech['eng']"
      ],
      "metadata": {
        "id": "-hSw_4biitXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/book_info.json', 'r', encoding='utf-8') as jsonfile:\n",
        "  book_info = json.load(jsonfile)"
      ],
      "metadata": {
        "id": "YCXMnAlBKrXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "xFhR5UfYe_sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/charmapping.json') as f:\n",
        "  charmap = json.load(f)\n",
        "\n",
        "def get_script(x, charmap):\n",
        "  scripts = []\n",
        "  for c in list(x):\n",
        "    if str(ord(c)) in charmap.keys():\n",
        "      scripts.append(charmap[str(ord(c))])\n",
        "  if len(scripts) > 0:\n",
        "    return(set(scripts))\n",
        "    #return max(set(scripts), key = scripts.count) \n",
        "  else:\n",
        "\n",
        "    return \"Unknown\""
      ],
      "metadata": {
        "id": "CAKeCXTXLD3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_script('''하나님께서 아기들을 죽이라는 바로의 명령을 따르지 않은 두 산파들을 기뻐하셔서 그들에게도 자녀의 축복을 주셨습니다.''', charmap)"
      ],
      "metadata": {
        "id": "8-uhikpde7Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_scripts = {}\n",
        "for lang in tqdm(list(bloom_audio.keys())):\n",
        "  lang_scripts[lang] =  {}\n",
        "  for itm in bloom_audio[lang]:\n",
        "    scr = get_script(itm['text'], charmap)\n",
        "    if not lang_scripts[lang].get(scr):\n",
        "      lang_scripts[lang][scr] = 0\n",
        "    lang_scripts[lang][scr] += 1\n",
        "\n",
        "print(lang_scripts)"
      ],
      "metadata": {
        "id": "9HbMUTEHLNTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in tqdm(list(lang_scripts.keys())):\n",
        "  mainscript = [x for x in lang_scripts[lang].keys() if lang_scripts[lang][x] == max(list(lang_scripts[lang].values()))][0]\n",
        "  print(f'{lang} uses {mainscript}')\n",
        "  for itm in bloom_audio[lang]:\n",
        "    if mainscript == get_script(itm['text'], charmap):\n",
        "      print(f'Here is an example: \\n✅ {itm[\"text\"]}')\n",
        "      break\n",
        "  if len(list(lang_scripts[lang].keys()))>1:\n",
        "    print('Here are counterexamples:')\n",
        "    for itm in bloom_audio[lang]:\n",
        "      if mainscript != get_script(itm['text'], charmap):\n",
        "        print('❌ ' + itm['text'])\n",
        "        if 'If you need somewhere to put more information about the book, you can use this page, which is the outside of the back cover.' in itm['text']:\n",
        "          print(itm['url'])"
      ],
      "metadata": {
        "id": "nbTrlAMhMvtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ldml.api.sil.org/langtags.json /content/langtags.json"
      ],
      "metadata": {
        "id": "7THGYM_4az6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('langtags.json', 'r', encoding='utf-8') as jsonfile:\n",
        "  langtags = json.load(jsonfile)"
      ],
      "metadata": {
        "id": "b3-rmww6bD6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langtags[10]"
      ],
      "metadata": {
        "id": "HxCdV-CucUBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/bloom_speech_aws.json', 'r', encoding='utf-8') as jsonfile:\n",
        "  bloom_speech = json.load(jsonfile)"
      ],
      "metadata": {
        "id": "zey1FL3mU75u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(list(bloom_speech.keys())) - set(biblnlp_langs))\n",
        "print(len(set(list(bloom_speech.keys())) - set(biblnlp_langs)))"
      ],
      "metadata": {
        "id": "zA1iX9HkVMiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext"
      ],
      "metadata": {
        "id": "FxL__1eUjYU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lid = fasttext.load_model('/content/drive/MyDrive/bloom/lid.176.bin')"
      ],
      "metadata": {
        "id": "387HhP5kjukL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lid.predict(bloom_speech['eng'][0]['text'], k=5)"
      ],
      "metadata": {
        "id": "7idu75rulhff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred[0][0]"
      ],
      "metadata": {
        "id": "xt-HZ3N5mhBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_predicts = {}\n",
        "for lang in tqdm(list(bloom_speech.keys())):\n",
        "  lang_predicts[lang] = {}\n",
        "  for idx, rec in enumerate(bloom_speech[lang]):\n",
        "    book = rec['book']\n",
        "    pred = lid.predict(rec['text'].replace('\\n', ' '), k=5)\n",
        "    for i in range(0,len(pred[0])):\n",
        "      tag = pred[0][i].split('_')[-1]\n",
        "      label = tag_to_iso.get(tag,tag)\n",
        "      if not lang_predicts[lang].get(book):\n",
        "        lang_predicts[lang][book] = {}\n",
        "      if not lang_predicts[lang][book].get(label):\n",
        "        lang_predicts[lang][book][label] = []\n",
        "      lang_predicts[lang][book][label].append(pred[1][i])\n"
      ],
      "metadata": {
        "id": "31743nHOkqhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_scripts = {}\n",
        "for lang in tqdm(list(bloom_speech.keys())):\n",
        "  lang_scripts[lang] =  {}\n",
        "  for itm in bloom_speech[lang]:\n",
        "    scr = get_script(itm['text'], charmap)\n",
        "    if not lang_scripts[lang].get(scr):\n",
        "      lang_scripts[lang][scr] = 0\n",
        "    lang_scripts[lang][scr] += 1\n",
        "\n",
        "print(lang_scripts)"
      ],
      "metadata": {
        "id": "SjrflJvluU_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "3A7fe9oWn_Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removenewline(input):\n",
        "  return(input.replace('\\n', ' '))"
      ],
      "metadata": {
        "id": "8i_oox21I29k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predslist =[]\n",
        "lplist = []\n",
        "qbooks = {}\n",
        "\n",
        "langlist = list(lang_predicts.keys())\n",
        "langlist.sort()\n",
        "\n",
        "with open('language_cleaning.txt', 'w', encoding = 'utf-8') as outfile:\n",
        "  for lang in langlist:\n",
        "    lpred = {x:[] for y in lang_predicts[lang].keys() for x in lang_predicts[lang][y].keys()}\n",
        "    for book in lang_predicts[lang].keys():\n",
        "      for label in lang_predicts[lang][book].keys():\n",
        "        lpred[label].extend(lang_predicts[lang][book][label])\n",
        "    maxlpred = max([len(lpred[x]) for x in lpred.keys()])\n",
        "    maxlpid= [x for x in lpred.keys() if len(lpred[x]) == maxlpred][0]\n",
        "    print(f'{lang} most frequently predicts {maxlpid} with average score of {sum(lpred[maxlpid])/len(lpred[maxlpid])}')\n",
        "    outfile.write(f'{lang} most frequently predicts {maxlpid} with average score of {sum(lpred[maxlpid])/len(lpred[maxlpid])}\\n')\n",
        "    predslist = []\n",
        "    for book in lang_predicts[lang].keys():\n",
        "      maxpred = max([len(lang_predicts[lang][book][x]) for x in lang_predicts[lang][book].keys()])\n",
        "      maxpid= [x for x in lang_predicts[lang][book].keys() if len(lang_predicts[lang][book][x]) == maxpred][0]\n",
        "      avgscore = sum(lang_predicts[lang][book][maxpid])/len(lang_predicts[lang][book][maxpid])\n",
        "      if lang != maxpid and avgscore > 0.45:\n",
        "        predslist.append(f'\\t{lang} {book} predicts {maxpid} with avg score:{sum(lang_predicts[lang][book][maxpid])/len(lang_predicts[lang][book][maxpid])}')\n",
        "        if (maxpid == 'eng' and lang != 'eng') or (maxpid == 'spa' and lang != 'spa') or (lang == 'spa' and maxpid != 'spa') or (lang=='eng' and maxpid !='eng'):\n",
        "          if not qbooks.get(lang):\n",
        "            qbooks[lang] = []\n",
        "          qbooks[lang].append(book)\n",
        "      else:\n",
        "        if lang == 'eng' and maxpid != 'eng' and any([x > 0.6 for x in lang_predicts[lang][book][maxpid]]):\n",
        "          for rec in bloom_speech[lang]:\n",
        "            if rec['book'] == book:\n",
        "              pred = lid.predict(rec['text'].replace('\\n', ' '), k=5)\n",
        "              tag = pred[0][0].split('_')[-1]\n",
        "              label = tag_to_iso.get(tag,tag)\n",
        "              if label != 'eng' and pred[1][0] > 0.6:\n",
        "                print(f'\\t{lang} {book} {label} outlier: {removenewline(rec[\"text\"])} score: {pred[1][0]}')\n",
        "                outfile.write(f'\\t{lang} {book} {label} outlier: {removenewline(rec[\"text\"])} score: {pred[1][0]}\\n')\n",
        "        elif lang == 'spa' and maxpid != 'spa' and any([x > 0.6 for x in lang_predicts[lang][book][maxpid]]):\n",
        "          for rec in bloom_speech[lang]:\n",
        "            if rec['book'] == book:\n",
        "              pred = lid.predict(rec['text'].replace('\\n', ' '), k=5)\n",
        "              tag = pred[0][0].split('_')[-1]\n",
        "              label = tag_to_iso.get(tag,tag)\n",
        "              if label != 'spa' and pred[1][0] > 0.6:\n",
        "                print(f'\\t{lang} {book} {label} outlier: {removenewline(rec[\"text\"])} score: {pred[1][0]}')\n",
        "                outfile.write(f'\\t{lang} {book} {label} outlier: {removenewline(rec[\"text\"])} score: {pred[1][0]}\\n')\n",
        "        elif lang != 'spa' and lang != 'eng' and (maxpid == 'eng' or maxpid == 'spa') and any([x > 0.6 for x in lang_predicts[lang][book][maxpid]]):\n",
        "          for rec in bloom_speech[lang]:\n",
        "            if rec['book'] == book:\n",
        "              pred = lid.predict(rec['text'].replace('\\n', ' '), k=5)\n",
        "              tag = pred[0][0].split('_')[-1]\n",
        "              label = tag_to_iso.get(tag,tag)\n",
        "              if (label == 'spa' or label == 'eng') and pred[1][0] > 0.6:\n",
        "                print(f'\\t{lang} {book} {label} outlier: {removenewline(rec[\"text\"])} score: {pred[1][0]}')\n",
        "                outfile.write(f'\\t{lang} {book} {label} outlier: {removenewline(rec[\"text\"])} score: {pred[1][0]}\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if predslist != []:\n",
        "      predslist.sort()\n",
        "      for line in predslist:\n",
        "        print(line)\n",
        "        outfile.write(line + '\\n')"
      ],
      "metadata": {
        "id": "9kzfQ1LGoTKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in list(book_info.keys()):\n",
        "  tag = lang.split('-')[0]\n",
        "  iso = tag_to_iso.get(tag)\n",
        "  if iso == None:\n",
        "    book_info.pop(lang)\n",
        "  elif iso != lang:\n",
        "    if not book_info.get(iso):\n",
        "      book_info[iso] = {}\n",
        "    book_info[iso].update(book_info.pop(lang))\n",
        "\n"
      ],
      "metadata": {
        "id": "lArhZZYUMdvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in qbooks:\n",
        "  langbookset = {x['book'] for x in bloom_speech[lang]}\n",
        "  print(f'{lang}:{len(qbooks[lang])} of {len(list(langbookset))}')\n"
      ],
      "metadata": {
        "id": "U7_B0R5SWjzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in book_info.keys():\n",
        "  for book in book_info[lang].keys():\n",
        "    if book in qbooks.get(lang,[]):\n",
        "      book_info[lang][book]['quarantine'] = True\n",
        "    else:\n",
        "      book_info[lang][book]['quarantine'] = False\n"
      ],
      "metadata": {
        "id": "rQ4q-qkMYxXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_info['tpi']"
      ],
      "metadata": {
        "id": "HTV6hz9oZcuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in list(set(book_info.keys())-set(bloom_speech.keys())):\n",
        "  book_info.pop(lang)"
      ],
      "metadata": {
        "id": "Kh28NBUDkFbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_info.keys()"
      ],
      "metadata": {
        "id": "sHUVzFiViAK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi_sort = list(book_info.keys())\n",
        "bi_sort.sort()\n",
        "print(bi_sort)"
      ],
      "metadata": {
        "id": "SIjCtZ8wPwJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(book_info.keys())-set(bloom_speech.keys()))\n",
        "print(set(bloom_speech.keys())-set(book_info.keys()))"
      ],
      "metadata": {
        "id": "Tm3vp0tcNGse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_info['bam']"
      ],
      "metadata": {
        "id": "-6oahDRDQF4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "import datasets"
      ],
      "metadata": {
        "id": "QkiZJ3zO4fne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.load_dataset('')"
      ],
      "metadata": {
        "id": "fwPMcywK4mOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_speech['bis']"
      ],
      "metadata": {
        "id": "h5hC61LjlvDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(book_info['ajz'])"
      ],
      "metadata": {
        "id": "Iwuly0gNPEUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_info['ajz']"
      ],
      "metadata": {
        "id": "9_vXBDJEOrJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lpred[maxlpid]"
      ],
      "metadata": {
        "id": "3Z653jhe5H7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(lang_predicts['eng']['eng'])"
      ],
      "metadata": {
        "id": "cZTDpjtdtQm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rec in bloom_speech['bjn']:\n",
        "  pred = lid.predict(rec['text'].replace('\\n', ' '), k=5)\n",
        "  tag = pred[0][0].split('_')[-1]\n",
        "  label = tag_to_iso.get(tag,tag)\n",
        "  if label == 'eng' and float(pred[1][0]) > 0.5:\n",
        "    print(rec['book'], rec['text'].replace('\\n', ' '))\n",
        "  "
      ],
      "metadata": {
        "id": "J8n2mRMTvjj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langtag_dict = {x['full']:x['iso639_3'] for x in langtags if x.get('full') and x.get('iso639_3')}\n",
        "shorttag_dict = {x['full']:x['tag'] for x in langtags if x.get('full') and x.get('tag')}\n",
        "tag_to_iso = {x['tag']:x['iso639_3'] for x in langtags if x.get('iso639_3') and x.get('tag')}\n",
        "iso_to_tag = {x['iso639_3']:x['tag'].split('-')[0] for x in langtags if x.get('iso639_3') and x.get('tag')}"
      ],
      "metadata": {
        "id": "pY2t5bF8bP1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/bloom_speech_aws.json', 'r', encoding='utf-8') as jsonfile:\n",
        "  bloom_speech = json.load(jsonfile)"
      ],
      "metadata": {
        "id": "f9E7XNlw6YqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/book_info.json', 'r', encoding='utf-8') as jsonfile:\n",
        "  book_info = json.load(jsonfile)"
      ],
      "metadata": {
        "id": "b0M6wbn3Ej8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "biblnlp_langs = ['aau', 'aaz', 'abx', 'aby', 'acf', 'acu', 'adz', 'aey', 'agd', 'agg', 'agm', 'agn', 'agr', 'agu', 'aia', 'ake', 'alp', 'alq', 'als', 'aly', 'ame', 'amk', 'amp', 'amr', 'amu', 'anh', 'anv', 'aoi', 'aoj', 'apb', 'apn', 'apu', 'apy', 'arb', 'arl', 'arn', 'arp', 'aso', 'ata', 'atb', 'atd', 'atg', 'auc', 'aui', 'auy', 'avt', 'awb', 'awk', 'awx', 'azg', 'azz', 'bao', 'bbb', 'bbr', 'bch', 'bco', 'bdd', 'bea', 'bel', 'bgs', 'bgt', 'bhg', 'bhl', 'big', 'bjr', 'bjv', 'bkd', 'bki', 'bkq', 'bkx', 'bla', 'blw', 'blz', 'bmh', 'bmk', 'bmr', 'bnp', 'boa', 'boj', 'bon', 'box', 'bqc', 'bre', 'bsn', 'bsp', 'bss', 'buk', 'bus', 'bvr', 'bxh', 'byx', 'bzd', 'bzj', 'cab', 'caf', 'cao', 'cap', 'car', 'cav', 'cax', 'cbc', 'cbi', 'cbk', 'cbr', 'cbs', 'cbt', 'cbu', 'cbv', 'cco', 'ces', 'cgc', 'cha', 'chd', 'chf', 'chk', 'chq', 'chz', 'cjo', 'cjv', 'cle', 'clu', 'cme', 'cmn', 'cni', 'cnl', 'cnt', 'cof', 'con', 'cop', 'cot', 'cpa', 'cpb', 'cpc', 'cpu', 'crn', 'crx', 'cso', 'cta', 'ctp', 'ctu', 'cub', 'cuc', 'cui', 'cut', 'cux', 'cwe', 'daa', 'dad', 'dah', 'ded', 'deu', 'dgr', 'dgz', 'dif', 'dik', 'dji', 'djk', 'dob', 'dwr', 'dww', 'dwy', 'eko', 'emi', 'emp', 'eng', 'epo', 'eri', 'ese', 'etr', 'faa', 'fai', 'far', 'for', 'fra', 'fuf', 'gai', 'gam', 'gaw', 'gdn', 'gdr', 'geb', 'gfk', 'ghs', 'gia', 'glk', 'gmv', 'gng', 'gnn', 'gnw', 'gof', 'grc', 'gub', 'guh', 'gui', 'gul', 'gum', 'guo', 'gvc', 'gvf', 'gwi', 'gym', 'gyr', 'hat', 'haw', 'hbo', 'hch', 'heb', 'heg', 'hix', 'hla', 'hlt', 'hns', 'hop', 'hrv', 'hub', 'hui', 'hus', 'huu', 'huv', 'hvn', 'ign', 'ikk', 'ikw', 'imo', 'inb', 'ind', 'ino', 'iou', 'ipi', 'ita', 'jac', 'jao', 'jic', 'jiv', 'jpn', 'jvn', 'kaq', 'kbc', 'kbh', 'kbm', 'kdc', 'kde', 'kdl', 'kek', 'ken', 'kew', 'kgk', 'kgp', 'khs', 'kje', 'kjs', 'kkc', 'kky', 'klt', 'klv', 'kms', 'kmu', 'kne', 'knf', 'knj', 'kos', 'kpf', 'kpg', 'kpj', 'kpw', 'kqa', 'kqc', 'kqf', 'kql', 'kqw', 'ksj', 'ksr', 'ktm', 'kto', 'kud', 'kue', 'kup', 'kvn', 'kwd', 'kwf', 'kwi', 'kwj', 'kyf', 'kyg', 'kyq', 'kyz', 'kze', 'lac', 'lat', 'lbb', 'leu', 'lex', 'lgl', 'lid', 'lif', 'lww', 'maa', 'maj', 'maq', 'mau', 'mav', 'maz', 'mbb', 'mbc', 'mbh', 'mbl', 'mbt', 'mca', 'mcb', 'mcd', 'mcf', 'mcp', 'mdy', 'med', 'mee', 'mek', 'meq', 'met', 'meu', 'mgh', 'mgw', 'mhl', 'mib', 'mic', 'mie', 'mig', 'mih', 'mil', 'mio', 'mir', 'mit', 'miz', 'mjc', 'mkn', 'mks', 'mlh', 'mlp', 'mmx', 'mna', 'mop', 'mox', 'mph', 'mpj', 'mpm', 'mpp', 'mps', 'mpx', 'mqb', 'mqj', 'msb', 'msc', 'msk', 'msm', 'msy', 'mti', 'muy', 'mva', 'mvn', 'mwc', 'mxb', 'mxp', 'mxq', 'mxt', 'myu', 'myw', 'myy', 'mzz', 'nab', 'naf', 'nak', 'nay', 'nbq', 'nca', 'nch', 'ncj', 'ncl', 'ncu', 'ndj', 'nfa', 'ngp', 'ngu', 'nhg', 'nhi', 'nho', 'nhr', 'nhu', 'nhw', 'nhy', 'nif', 'nin', 'nko', 'nld', 'nlg', 'nna', 'nnq', 'not', 'nou', 'npl', 'nsn', 'nss', 'ntj', 'ntp', 'nwi', 'nyu', 'obo', 'ong', 'ons', 'ood', 'opm', 'ote', 'otm', 'otn', 'otq', 'ots', 'pab', 'pad', 'pah', 'pao', 'pes', 'pib', 'pio', 'pir', 'pjt', 'plu', 'pma', 'poe', 'poi', 'pon', 'poy', 'ppo', 'prf', 'pri', 'ptp', 'ptu', 'pwg', 'quc', 'quf', 'quh', 'qul', 'qup', 'qvc', 'qve', 'qvh', 'qvm', 'qvn', 'qvs', 'qvw', 'qvz', 'qwh', 'qxh', 'qxn', 'qxo', 'rai', 'rkb', 'rmc', 'roo', 'rop', 'rro', 'ruf', 'rug', 'rus', 'sab', 'san', 'sbe', 'seh', 'sey', 'sgz', 'shj', 'shp', 'sim', 'sja', 'sll', 'smk', 'snc', 'snn', 'sny', 'som', 'soq', 'spa', 'spl', 'spm', 'sps', 'spy', 'sri', 'srm', 'srn', 'srp', 'srq', 'ssd', 'ssg', 'ssx', 'stp', 'sua', 'sue', 'sus', 'suz', 'swe', 'swh', 'swp', 'sxb', 'tac', 'tav', 'tbc', 'tbl', 'tbo', 'tbz', 'tca', 'tee', 'ter', 'tew', 'tfr', 'tgp', 'tif', 'tim', 'tiy', 'tke', 'tku', 'tna', 'tnc', 'tnn', 'tnp', 'toc', 'tod', 'toj', 'ton', 'too', 'top', 'tos', 'tpt', 'trc', 'tsw', 'ttc', 'tue', 'tuo', 'txu', 'ubr', 'udu', 'ukr', 'uli', 'ura', 'urb', 'usa', 'usp', 'uvl', 'vid', 'vie', 'viv', 'vmy', 'waj', 'wal', 'wap', 'wat', 'wbp', 'wed', 'wer', 'wim', 'wmt', 'wmw', 'wnc', 'wnu', 'wos', 'wrk', 'wro', 'wsk', 'wuv', 'xav', 'xed', 'xla', 'xnn', 'xon', 'xsi', 'xtd', 'xtm', 'yaa', 'yad', 'yal', 'yap', 'yaq', 'yby', 'ycn', 'yka', 'yml', 'yre', 'yuj', 'yut', 'yuw', 'yva', 'zaa', 'zab', 'zac', 'zad', 'zai', 'zaj', 'zam', 'zao', 'zar', 'zas', 'zat', 'zav', 'zaw', 'zca', 'zia', 'ziw', 'zos', 'zpc', 'zpl', 'zpo', 'zpq', 'zpu', 'zpv', 'zpz', 'zsr', 'ztq', 'zty', 'zyp']\n",
        "print(len(biblnlp_langs))"
      ],
      "metadata": {
        "id": "W49Tnx1l62lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lics = set()\n",
        "lang_counts = {}\n",
        "rem_books = set()\n",
        "rem_langs = set()\n",
        "for lang in book_info:\n",
        "  lang_counts[lang] = {'all':0, 'nd':0}\n",
        "  for key in book_info[lang].keys():\n",
        "    lang_counts[lang]['all']+=1\n",
        "    lics.add(book_info[lang][key]['license'])\n",
        "    if book_info[lang][key]['license'] == 'cc-by-nc-nd':\n",
        "      print(key)\n",
        "      lang_counts[lang]['nd']+=1\n",
        "      rem_books.add(key)\n",
        "\n",
        "print(lics)\n",
        "print(lang_counts)\n",
        "for lang in lang_counts:\n",
        "  if lang_counts[lang]['all'] == lang_counts[lang]['nd']:\n",
        "    print(f'remove {lang}')\n",
        "    rem_langs.add(lang)"
      ],
      "metadata": {
        "id": "Jd61Q0GfEtH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in book_info:\n",
        "  if lang in rem_langs"
      ],
      "metadata": {
        "id": "xC94Js1yIKIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langlist = []\n",
        "dict2to3 = {}\n",
        "for lang in bloom_speech:\n",
        "  langlist.append(lang)\n",
        "  tag = iso_to_tag.get(lang, lang)\n",
        "  if len(tag) == 2:\n",
        "    langlist.append(tag)\n",
        "    dict2to3.update({tag:lang})\n",
        "\n",
        "langlist.sort()\n",
        "print(langlist)\n",
        "print(dict2to3)"
      ],
      "metadata": {
        "id": "8ySG6df97YKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(book_info['ajz'])"
      ],
      "metadata": {
        "id": "HTNoA0oOivRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(langlist))"
      ],
      "metadata": {
        "id": "eVI-puFJ_oQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in bloom_audio.keys():\n",
        "  tag = lang.split('-')[0]\n",
        "  print(f'{tag} - {tag_to_iso.get(tag)}')"
      ],
      "metadata": {
        "id": "Kx0Rchf1cen4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_speech = {}\n",
        "lang_texts = {}\n",
        "for lang in tqdm(list(bloom_audio.keys())):\n",
        "  tag = lang.split('-')[0]\n",
        "  iso = tag_to_iso.get(tag)\n",
        "  if not bloom_speech.get(iso) and iso is not None:\n",
        "    bloom_speech[iso] = []\n",
        "    lang_texts[iso] = set()\n",
        "  mainscript = [x for x in lang_scripts[lang].keys() if lang_scripts[lang][x] == max(list(lang_scripts[lang].values()))][0]\n",
        "  for itm in bloom_audio[lang]:\n",
        "    txt = itm['text']\n",
        "    if 'If you need somewhere to put more information about the book, you can use this page, which is the outside of the back cover.' in txt:\n",
        "      txt = txt.split('If you need somewhere to put more information about the book, you can use this page, which is the outside of the back cover.')[0]\n",
        "    if any([x.isdigit() for x in itm['text']]):\n",
        "      hasdigit = True\n",
        "    else:\n",
        "      hasdigit = False\n",
        "    if iso is not None and (mainscript == get_script(txt, charmap) or all([x.isdigit() for x in itm['text']])):\n",
        "      if txt not in lang_texts[iso]:\n",
        "        bloom_speech[iso].append({'book':itm['book'], 'text': txt, 'url':itm['url'], 'containsNumber': hasdigit, 'bloomLanguageTag': lang})\n",
        "        lang_texts[iso].add(txt)\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/bloom_speech.json', 'w', encoding='utf-8') as jsonfile:\n",
        "  json.dump(bloom_speech,jsonfile)"
      ],
      "metadata": {
        "id": "rBI2QMs-WAK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_counts = {}\n",
        "for lang in bloom_speech:\n",
        "  speech_counts[lang] = len(list(bloom_speech[lang]))\n",
        "\n",
        "bcl = [f'{k}:{v}' for k,v in speech_counts.items()]\n",
        "bcl.sort()\n",
        "print(bcl)"
      ],
      "metadata": {
        "id": "fVEWoFpZgYJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lis = [1,2,3]\n",
        "print(lis[-0:])"
      ],
      "metadata": {
        "id": "tlzfBuqho3Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "used_keys = set()\n",
        "failed_urls = {}\n",
        "for lang in tqdm(list(bloom_speech.keys())):\n",
        "  for idx, rec in enumerate(bloom_speech[lang]):\n",
        "    i = 0\n",
        "    filename = f'{lang}-0000-{rec[\"url\"].split(\"/\")[-1]}'\n",
        "    while filename in used_keys:\n",
        "      i += 1\n",
        "      filename = f'{lang}-{i:04d}-{rec[\"url\"].split(\"/\")[-1]}'\n",
        "    page = requests.get(rec['url'])\n",
        "    if page.status_code == 200:\n",
        "      with open('temp.mp3', 'wb') as aud:\n",
        "        aud.write(page.content)\n",
        "      client.upload_file('temp.mp3','bloom-speech', f'audio/{filename}')\n",
        "      bloom_speech[lang][idx]['url'] = f'https://s3.amazonaws.com/bloom-speech/audio/{filename}'\n",
        "    else:\n",
        "      failed_urls[rec['url']] = filename\n",
        "      with open('/content/drive/MyDrive/bloom/failed_urls.json', 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(failed_urls, jsonfile)\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/bloom_speech_aws.json', 'w', encoding='utf-8') as jsonfile:\n",
        "  json.dump(bloom_speech, jsonfile)\n",
        "\n"
      ],
      "metadata": {
        "id": "28Lsi19gj_8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(failed_urls)"
      ],
      "metadata": {
        "id": "XxkfQw8SnMB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poplist = []\n",
        "for key in failed_urls.keys():\n",
        "  if key.startswith('https://s3'):\n",
        "    poplist.append(key)\n",
        "\n",
        "for key in poplist:\n",
        "  failed_urls.pop(key)\n",
        "\n",
        "print(len(list(failed_urls.keys())))"
      ],
      "metadata": {
        "id": "oZgNggH3Wdtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in tqdm(list(bloom_speech.keys())):\n",
        "  for idx, rec in enumerate(bloom_speech[lang]):\n",
        "    if failed_urls.get(rec['url']):\n",
        "      page = requests.get(rec['url'])\n",
        "      if page.status_code == 200:\n",
        "        oldurl = rec['url']\n",
        "        with open('temp.mp3', 'wb') as aud:\n",
        "          aud.write(page.content)\n",
        "        client.upload_file('temp.mp3','bloom-speech', f'audio/{filename}')\n",
        "        bloom_speech[lang][idx]['url'] = f'https://s3.amazonaws.com/bloom-speech/audio/{filename}'\n",
        "        failed_urls.pop(oldurl)\n",
        "        with open('/content/drive/MyDrive/bloom/failed_urls.json', 'w', encoding='utf-8') as jsonfile:\n",
        "          json.dump(failed_urls, jsonfile)\n",
        "      else:\n",
        "        print(f'{rec[\"url\"]} failed again')\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/bloom_speech_aws.json', 'w', encoding='utf-8') as jsonfile:\n",
        "  json.dump(bloom_speech, jsonfile)\n",
        "      \n"
      ],
      "metadata": {
        "id": "HcSgrguAL6gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.upload_file('/content/drive/MyDrive/bloom/book_info.json', 'bloom-speech', 'book_info.json')\n",
        "client.upload_file('/content/drive/MyDrive/bloom/bloom_speech_aws.json', 'bloom-speech', 'bloom_speech.json')"
      ],
      "metadata": {
        "id": "i8dmy716XIJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_info.keys()"
      ],
      "metadata": {
        "id": "zZ-zOJb6Unmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/book_info.json', 'w', encoding='utf-8') as jsonfile:\n",
        "  json.dump(book_info, jsonfile)"
      ],
      "metadata": {
        "id": "GRDOKAHGUpnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.upload_file('/content/drive/MyDrive/bloom/book_info.json', 'bloom-speech', 'book_info.json')"
      ],
      "metadata": {
        "id": "G4OY7aaASrzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "print(f'{i:04d}')"
      ],
      "metadata": {
        "id": "c7k99OzMmhEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_audio['qaa']"
      ],
      "metadata": {
        "id": "wMW1WpUuXqWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_counts = {}\n",
        "for lang in book_info:\n",
        "  book_counts[lang] = len(list(book_info[lang].keys()))\n",
        "\n",
        "bcl = [f'{k}:{v}' for k,v in book_counts.items()]\n",
        "bcl.sort()\n",
        "print(bcl)"
      ],
      "metadata": {
        "id": "NyTGCqMsfM8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in tqdm(list(bloom_audio.keys())):\n",
        "  urlset = {x['url'] for x in bloom_audio[lang]}\n",
        "  fileset = {'/'.join(y['url'].split('/')[-4:]) for y in bloom_audio[lang]}\n",
        "  if len(list(urlset)) != len(list(fileset)):\n",
        "    reuse = 0   \n",
        "    textdict = {x:set() for x in fileset}\n",
        "    urldict = {x:set() for x in fileset}\n",
        "    for rec in bloom_audio[lang]:\n",
        "      textdict['/'.join(rec['url'].split('/')[-4:])].add(rec['text'])\n",
        "      urldict['/'.join(rec['url'].split('/')[-4:])].add(rec['book'])\n",
        "    for k,v in textdict.items():\n",
        "      if len(list(v)) > 1:\n",
        "        reuse += 1\n",
        "        #print(k)\n",
        "        print(textdict[k])\n",
        "        print(urldict[k])\n",
        "    if reuse == 0:\n",
        "      print(f'{lang} ✅')\n",
        "    else:\n",
        "      print(f'{lang} ❌ urlset: {len(list(urlset))} fileset: {len(list(fileset))}. {reuse} reused.')  \n",
        "    \n",
        "  else:\n",
        "    print(f'{lang} ✅')"
      ],
      "metadata": {
        "id": "wb4pR4HlKwZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2lang = {}\n",
        "for lang in tqdm(list(bloom_audio.keys())):\n",
        "  for rec in bloom_audio[lang]:\n",
        "    if not text2lang.get(rec['text']):\n",
        "      text2lang[rec['text']] = set()\n",
        "    text2lang[rec['text']].add(lang)\n",
        "\n",
        "for text in list(text2lang.keys()):\n",
        "  if len(list(text2lang[text])) > 1:\n",
        "    print(f'{text} appears in {list(text2lang[text])}')"
      ],
      "metadata": {
        "id": "x9hmg34nS7oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_speech = {}\n",
        "texts = {}\n",
        "langurls = set()\n",
        "\n",
        "for lang in tqdm(list(bloom_audio.keys()):\n",
        "  texts[lang] = set()\n",
        "  for rec in bloom_audio[lang]:\n",
        "    if rec['url'] not in langurls:\n",
        "      if rec['text'] not in texts[lang]:\n",
        "        page = requests.get(rec['url'])\n",
        "        if page.status_code == 200:\n",
        "          with open('temp.mp3', 'wb') as aud:\n",
        "            aud.write(page.content)\n",
        "          client.upload_file\n",
        "\n"
      ],
      "metadata": {
        "id": "sLJTzkWlDs4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instset = {}\n",
        "instdict\n",
        "for lang in book_info:\n",
        "  instset[lang] = set()\n",
        "  for key in book_info[lang].keys():\n",
        "    if book_info[lang][key].get('instance') and book_info[lang][key].get('instance') in instset[lang]:\n",
        "      print(f'{lang} {book_info[lang][key][\"instance\"]} repeats')\n",
        "    else:\n",
        "      instset[lang].add(book_info[lang][key].get('instance'))"
      ],
      "metadata": {
        "id": "ofsnlhagdzZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(urls))"
      ],
      "metadata": {
        "id": "dc4EF8t8W-ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(set(urls)))"
      ],
      "metadata": {
        "id": "u9a73M8bYeRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(set(badurls)))"
      ],
      "metadata": {
        "id": "hos08g3ifVjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(badurls[:10])"
      ],
      "metadata": {
        "id": "hSGGZxd9mlV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/bloom/bad_urls.pkl', 'wb') as pklfile:\n",
        "  pickle.dump(badurls, pklfile)\n",
        "\n",
        "with open('/content/drive/MyDrive/bloom/bad_books.pkl', 'wb') as pklfile:\n",
        "  pickle.dump(prob_books, pklfile)"
      ],
      "metadata": {
        "id": "2uM1I3ktmR1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(prob_books.keys())))"
      ],
      "metadata": {
        "id": "c-qfuz1Qkxd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_books = [bloom_audio[x][y]['book'] for x in list(bloom_audio.keys()) for y in range(len(bloom_audio[x]))]"
      ],
      "metadata": {
        "id": "g1RpBLRYH8dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(prob_books.keys() - set(good_books)))"
      ],
      "metadata": {
        "id": "TArtErGaI9Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_set = set()\n",
        "for lang in bloom_audio.keys():\n",
        "  for record in bloom_audio[lang]:\n",
        "    book_set.add(record.get('book'))\n",
        "\n",
        "print(book_set)"
      ],
      "metadata": {
        "id": "z3IComX5-iWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Pagluto' in books"
      ],
      "metadata": {
        "id": "Tsud_ZyHmmqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = requests.get('https://bloomlibrary.org/talking-books')"
      ],
      "metadata": {
        "id": "LFH-_zqCFkUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/talking_books.html', 'r') as htmlfile:\n",
        "  soup = BeautifulSoup(htmlfile, 'html.parser' )"
      ],
      "metadata": {
        "id": "xvxHWZKcAAPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page."
      ],
      "metadata": {
        "id": "3HLHu0DcCep8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_book_set = set()\n",
        "for link in soup.findAll(attrs={'class':'css-1ywcju2'}):\n",
        "  full_book_set.add(link.get_text().strip())"
      ],
      "metadata": {
        "id": "uPrjs8dZAQ3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(full_book_set)), len(list(book_set)), len(list(full_book_set - book_set)))"
      ],
      "metadata": {
        "id": "q9VFQQvbCOKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fb_list = list(full_book_set)\n",
        "bs_list = list(book_set)\n",
        "fb_list.sort()\n",
        "bs_list.sort()\n",
        "print(fb_list)\n",
        "print(bs_list)"
      ],
      "metadata": {
        "id": "Pz0bBO4nlwcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_book_set - book_set)\n",
        "print(book_set - full_book_set)"
      ],
      "metadata": {
        "id": "SEQ6CIxhFSZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_books = []\n",
        "notparsed_books = []\n",
        "for book in list(full_book_set-book_set):\n",
        "  if book not in books:\n",
        "    missing_books.append(book)\n",
        "  else:\n",
        "    notparsed_books.append(book)\n"
      ],
      "metadata": {
        "id": "5TJRoR3iHIOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(missing_books), len(notparsed_books))"
      ],
      "metadata": {
        "id": "asGo7VYBH0ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloom_dir = '/content/drive/MyDrive/bloom/bloom_downloads'\n",
        "books = os.listdir(bloom_dir)"
      ],
      "metadata": {
        "id": "Jvi3wHF_rqYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audiosent(tag):\n",
        "  return tag.has_attr('audio-sentence')"
      ],
      "metadata": {
        "id": "TVGaAD_FRMcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "tb_set = set()\n",
        "tb_lds = {}\n",
        "missing_lang = 0\n",
        "has_lang = 0\n",
        "ml_books = set()\n",
        "hl_books = set()\n",
        "lang_set = set()\n",
        "\n",
        "for book in tqdm(books):\n",
        "  metapath = os.path.join(bloom_dir, book, 'meta.json')\n",
        "  if os.path.isfile(metapath):\n",
        "    with open(metapath, 'rb') as jsonfile:\n",
        "      meta = json.load(jsonfile)\n",
        "    if meta.get('features'):\n",
        "      for feat in meta['features']:\n",
        "        if feat.startswith('talkingBook'):\n",
        "          tb_set.add(feat)\n",
        "          if not tb_lds.get(feat):\n",
        "            tb_lds[feat] = set()\n",
        "          langs = list(meta.get('language-display-names',{}).keys())\n",
        "          for lang in langs:\n",
        "            tb_lds[feat].add(lang)\n",
        "\n",
        "          titles = [x for x in os.listdir(os.path.join(bloom_dir, book)) if x.endswith('.htm')]\n",
        "          if titles == []:\n",
        "            print(f'{book} lacks .htm')\n",
        "            print(os.listdir(os.path.join(bloom_dir, book)))\n",
        "          else:\n",
        "            title=titles[0]\n",
        "            title_path = os.path.join(bloom_dir, book, title)\n",
        "            with open(title_path,'rb') as htmlfile:\n",
        "              soup = BeautifulSoup(htmlfile, 'html.parser')\n",
        "            for hit in soup.find_all(attrs={'class' : 'audio-sentence'}):\n",
        "              if hit != []:\n",
        "                if hit.attrs.get('lang') and hit.attrs.get('lang')!= '*':\n",
        "                  lang = hit.attrs.get('lang')\n",
        "                  id = hit.get_attribute_list('id')[0]\n",
        "                  text = hit.get_text().strip()\n",
        "                  has_lang += 1\n",
        "                  lang_set.add(lang)\n",
        "                  hl_books.add(book)\n",
        "                elif parents_havelang(hit): \n",
        "                  for parent in hit.parents:\n",
        "                    if parent.attrs.get('lang') and parent.attrs.get('lang') != '*':\n",
        "                      lang = parent.attrs.get('lang')\n",
        "                      break\n",
        "                  id = hit.get_attribute_list('id')[0]\n",
        "                  text = hit.get_text().strip()\n",
        "                  has_lang += 1\n",
        "                  lang_set.add(lang)\n",
        "                  hl_books.add(book)\n",
        "                #elif len(langs) == 1:\n",
        "                  #lang = langs[0]\n",
        "                  #id = hit.get_attribute_list('id')[0]\n",
        "                  #text = hit.get_text().strip()\n",
        "                  #has_lang += 1\n",
        "                  #lang_set.add(lang)\n",
        "                  #hl_books.add(book)\n",
        "                elif len([x for x in meta['features'] if x.startswith('talkingBook:')]) == 1:\n",
        "                  lang = [x.split(':')[1] for x in meta['features'] if x.startswith('talkingBook:')][0]\n",
        "                  id = hit.get_attribute_list('id')[0]\n",
        "                  text = hit.get_text().strip()\n",
        "                  has_lang += 1\n",
        "                  lang_set.add(lang)\n",
        "                  hl_books.add(book)\n",
        "                else:\n",
        "                  missing_lang += 1\n",
        "                  ml_books.add(book)\n",
        "\n",
        "          \n",
        "\n",
        "print(len(list(tb_set)))\n",
        "    "
      ],
      "metadata": {
        "id": "rOYEgkbU0jN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parent in hit.parents:\n",
        "  if parent.attrs.get('lang'):\n",
        "    print(parent.attrs.get('lang')\n",
        "  else:\n",
        "    print(parent.name, parent.attrs, parent.attrs.get('lang'))"
      ],
      "metadata": {
        "id": "cFvUjF4jj_3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(missing_lang)\n",
        "print(has_lang)\n",
        "print(len(list(lang_set)))\n",
        "print(len(list(ml_books-hl_books)))"
      ],
      "metadata": {
        "id": "FVoHhwOXWuxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lang_set)"
      ],
      "metadata": {
        "id": "xY9yNrcBgLqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_valid_set = {x.split('-')[0] for x in list(lang_set)}"
      ],
      "metadata": {
        "id": "4dyDUJGcsslW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_lower_set = {x.lower() for x in list(lang_set)}"
      ],
      "metadata": {
        "id": "TikkDIVttdKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lang_valid_set), len(lang_lower_set))"
      ],
      "metadata": {
        "id": "Kp32asDbtG8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 'blah'\n",
        "print(a.split('-')[0])"
      ],
      "metadata": {
        "id": "bVf0FOHms2Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "id": "8e9_mSE4YcoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_list = list(tb_set)\n",
        "tb_list.sort()\n",
        "print(tb_list)"
      ],
      "metadata": {
        "id": "sJneim7FBtrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tb_lds['talkingBook'])"
      ],
      "metadata": {
        "id": "I4eZyaO7CXkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_tagged = set([x.split(':')[1] for x in tb_lds.keys() if ':' in x])"
      ],
      "metadata": {
        "id": "m8iILMgSF_br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_out = list(tb_lds['talkingBook']-tb_tagged)\n",
        "tb_out.sort()\n",
        "print(tb_out)"
      ],
      "metadata": {
        "id": "YwaACKplGQmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/bloom/bloom_downloads/Ang Pamilya/'"
      ],
      "metadata": {
        "id": "QRZnjUVkD1mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat '/content/drive/MyDrive/bloom/bloom_downloads/Ang Pamilya/meta.json'"
      ],
      "metadata": {
        "id": "wOI4W8ScEAKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Missing Files checks"
      ],
      "metadata": {
        "id": "Htk2OvX1SgYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "licexl = set()\n",
        "nondisplay = set()\n",
        "noaudio = set()\n",
        "noretrieve = set()\n",
        "nolangtags = set()\n",
        "notextintags = set(notparsed_books)\n",
        "book_aud = {}\n",
        "for book in tqdm(notparsed_books):\n",
        "  book_aud[book] = {}\n",
        "  metapath = os.path.join(bloom_dir, book, 'meta.json')\n",
        "  if os.path.isfile(metapath):\n",
        "    with open(metapath, 'rb') as jsonfile:\n",
        "      meta = json.load(jsonfile)\n",
        "      if meta.get('license') in ['custom', 'ask', None]:\n",
        "        licexl.add(book)\n",
        "      downsrc = meta.get('downloadSource')\n",
        "  else:\n",
        "    print(f'No metadata for {book}')\n",
        "  titles = [x for x in os.listdir(os.path.join(bloom_dir, book)) if x.endswith('.htm')]\n",
        "  if titles == []:\n",
        "    print(f'{book} lacks .htm')\n",
        "    print(os.listdir(os.path.join(bloom_dir, book)))\n",
        "  else:\n",
        "    title=titles[0]\n",
        "    title_path = os.path.join(bloom_dir, book, title)\n",
        "    with open(title_path,'rb') as htmlfile:\n",
        "      soup = BeautifulSoup(htmlfile, 'html.parser')\n",
        "    if len(soup.findAll(attrs={'class' : 'audio-sentence'})) == 0:\n",
        "      noaudio.add(book)\n",
        "    else:\n",
        "      if not any([x.get_attribute_list('lang',False) for x in soup.findAll(attrs={'class': 'audio-sentence'})]):\n",
        "        nolangtags.add(book)\n",
        "  #foundfileids = [x.split('/')[-1].split('.')[0] for x in urls]\n",
        "  #fileids = [y.get_attribute_list('id')[0] for y in soup.findAll(attrs={'class' : 'audio-sentence'})]\n",
        "  #if len(set(fileids)-set(foundfileids)) == len(set(fileids)):\n",
        "  #  noretrieve.add(book)\n",
        "  if not meta.get('language-display-names'):\n",
        "    nondisplay.add(book)\n",
        "  else:\n",
        "    for lang in meta['language-display-names'].keys():\n",
        "      book_aud[book][lang] = False\n",
        "      for hit in soup.findAll(attrs={'lang': lang, 'class' : 'audio-sentence'}):\n",
        "        fileid = hit.get_attribute_list('id')[0]\n",
        "        text = hit.get_text().strip()                 \n",
        "        if text != '':\n",
        "          try:\n",
        "            notextintags.remove(book)\n",
        "          except:\n",
        "            pass\n",
        "          url = f'https://s3.amazonaws.com/bloomharvest/{downsrc}/bloomdigital/audio/{fileid}.mp3'\n",
        "        \n",
        "          page = requests.get(url)\n",
        "          if page.status_code == 200:\n",
        "            book_aud[book][lang] = True\n",
        "            break\n",
        "      for lhit in soup.findAll(attrs={'lang':lang}):\n",
        "        for hit in lhit.findAll(attrs={'class' : 'audio-sentence'}):\n",
        "          fileid = hit.get_attribute_list('id')[0]\n",
        "          text = hit.get_text().strip()                 \n",
        "          if text != '':\n",
        "            try:\n",
        "              notextintags.remove(book)\n",
        "            except:\n",
        "              pass\n",
        "            url = f'https://s3.amazonaws.com/bloomharvest/{downsrc}/bloomdigital/audio/{fileid}.mp3'\n",
        "          \n",
        "            page = requests.get(url)\n",
        "            if page.status_code == 200:\n",
        "              book_aud[book][lang] = True\n",
        "              break\n",
        "    if not any([book_aud[book][x] for x in list(book_aud[book].keys())]):\n",
        "      noretrieve.add(book)  \n",
        "                                                                 \n",
        "\n",
        "print(f'{len(licexl)} excluded because of license')\n",
        "print(f'{len(nondisplay)} lack language-display-names in metadata')\n",
        "print(f'{len(noaudio)} don\\'t have audio-sentence')\n",
        "print(f'{len(noretrieve)} had no valid urls')\n",
        "print(f'{len(nolangtags)} has no lang tags')\n",
        "print(f'{len(noaudio.union(nondisplay, licexl, noretrieve))} excluded of {len(notparsed_books)} books')"
      ],
      "metadata": {
        "id": "fCSvcegnIfUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(list(notparsed_books)) - noretrieve - noaudio - licexl - nondisplay)"
      ],
      "metadata": {
        "id": "7-ACr4hX3lCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tbook in set(list(notparsed_books)) - noretrieve:\n",
        "  with open(os.path.join(bloom_dir, tbook, 'meta.json'), 'rb') as jsonfile:\n",
        "    tmeta = json.load(jsonfile)\n",
        "  if tmeta.get('language-display-names'):\n",
        "    ld_keys = list(tmeta['language-display-names'].keys())\n",
        "    audio_keys = [x for x in list(book_aud[tbook].keys()) if book_aud[tbook][x]]\n",
        "    if any([x not in audio_keys for x in ld_keys]):\n",
        "      print(f'{tbook} has audio keys {audio_keys} and ld keys {ld_keys}')\n"
      ],
      "metadata": {
        "id": "EcCXcPBX32Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blah = set([1,2,3])\n",
        "blah.remove(1)\n",
        "print(blah)"
      ],
      "metadata": {
        "id": "sVbTyPiXxv6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(fileids))\n",
        "print(meta.get('downloadSource'))\n",
        "testfileids = fileids[:5]\n",
        "print(len(set(fileids)-set(testfileids)))\n",
        "print(len(set(fileids)))\n"
      ],
      "metadata": {
        "id": "MEQUKycMUFF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metapath = '/content/bloom_downloads/Inyawa/meta.json'\n",
        "title_path = '/content/bloom_downloads/Inyawa/Inyawa.htm'\n",
        "lang = 'cak'\n",
        "files=0\n",
        "\n",
        "with open(metapath, 'rb') as jsonfile:\n",
        "  meta = json.load(jsonfile)\n",
        "  downsrc = meta.get('downloadSource')\n",
        "\n",
        "with open(title_path,'rb') as htmlfile:\n",
        "  soup = BeautifulSoup(htmlfile, 'html.parser')\n",
        "#with open('/content/drive/MyDrive/bloom/all-lang-files.csv', 'a', encoding='utf-16') as csvfile:\n",
        "  #writer = csv.writer(csvfile, dialect='excel', delimiter='\\t')\n",
        "for lhit in soup.findAll(attrs={'lang':'cak'}):\n",
        "  for hit in lhit.findAll(attrs={'class' : 'audio-sentence'}):\n",
        "    #print(hit)\n",
        "    fileid = hit.get_attribute_list('id')[0]\n",
        "    text = hit.get_text().strip()                \n",
        "    if text != '':\n",
        "      url = f'https://s3.amazonaws.com/bloomharvest/{downsrc}/bloomdigital/audio/{fileid}.mp3'\n",
        "      page = requests.get(url)\n",
        "      if page.status_code == 200:\n",
        "        files += 1\n",
        "        print(text)\n",
        "        #if not bloom_audio.get(lang):\n",
        "      #   bloom_audio[lang]=[] \n",
        "      # bloom_audio[lang].append({\"book\": book, \"url\": url, \"text\": text})\n",
        "      #else:\n",
        "      #  print(f'{url} failed for {text}')\n",
        "print(files)"
      ],
      "metadata": {
        "id": "M43ZignTnjAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(os.path.join(bloom_dir,'Los tesoros del bosque/meta.json'))"
      ],
      "metadata": {
        "id": "k2sMZU4TXiCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.download_file('bloom-speech', 'bloom_speech.json', 'bloom_speech.json')"
      ],
      "metadata": {
        "id": "LTzWJD6D_s4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.download_file('bloom-speech', 'book_info.json', 'book_info.json')"
      ],
      "metadata": {
        "id": "SWbw3KsKBxFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bloom_speech.json', 'r') as f:\n",
        "  df = json.load(f)"
      ],
      "metadata": {
        "id": "TC0qV8eD_0yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('book_info.json', 'r') as f:\n",
        "  meta = json.load(f)"
      ],
      "metadata": {
        "id": "KfGnP-5qCDw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta['eng']['Instead of the Rooster']"
      ],
      "metadata": {
        "id": "VTf6tiDZCK7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.keys()"
      ],
      "metadata": {
        "id": "XaBdh4UiAfcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bam'][0]"
      ],
      "metadata": {
        "id": "NLPKlL0xBiFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in df.keys():\n",
        "  lics = {}\n",
        "  lictypes = set([meta[lang][x['book']]['license'] for x in df[lang]])\n",
        "  for lic in lictypes:\n",
        "    if not lics.get(lic):\n",
        "      lics[lic] = 0\n",
        "    lics[lic] += [meta[lang][x['book']]['license'] for x in df[lang]].count(lic)\n",
        "  print(lang, lics)"
      ],
      "metadata": {
        "id": "2vGQKLhZAvO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
